# ğŸ›ï¸ CoppelChallenge

Bienvenidos al proyecto del Challenge de Coppel, en este repositorio encontrarÃ¡s toda la infraestructura del cÃ³digo, esto engloba el procesamiento del ETL para generar los datos crudos (bronze), filtrados (silver) y preparados para el entrenamiento del modelo de Machine Learning (gold). AsÃ­ mismo, encontrarÃ¡s el cÃ³digo con el cual se construye una API, la cual se explica mÃ¡s adelante.
En cada Pull Request se llevan a cabo GitHub Actions los cuales contemplan Linting, Testing, Build de Docker y SonarCloud. AdemÃ¡s, la documentaciÃ³n de todo el proyecto se realiza usando Sphinx.

---

## âš™ï¸ Arquitectura del Proyecto

- **Bronze Layer**: Carga e ingesta de datos crudos desde CSV a SQLite (`ventas_bronze`).
- **Silver Layer**: Limpieza, validaciÃ³n y filtro de datos (`ventas_silver`).
- **Gold Layer**: Feature engineering y creaciÃ³n de la variable objetivo `Target_90Days` (`ventas_gold`) la cual representa el valor 1 (el cliente volverÃ¡ dentro de los prÃ³ximos 90 dÃ­as) y 0 (el cliente no regresarÃ¡).

---

## ğŸ¤– Entrenamiento del Modelo

Durante el entrenamiento del modelo se toman en cuenta tres posibles modelos:

- ClasificaciÃ³n binaria: `RandomForest`, `GradientBoosting` y `XGBoost`.

Una vez entrenados los tres modelos se selecciona el que mejor performance tenga en su precision. La razÃ³n por la cual se escogiÃ³ el precision como principal mÃ©trica es debido a la naturaleza del problema: para el negocio no es bueno predecir que alguien volverÃ¡ a comprar en los prÃ³ximos 90 dÃ­as y que en realidad no lo haga.
Finalmente el modelo seleccionado se guarda como un `model.pkl`.

---

## ğŸ§ª API REST (FastAPI)

### Endpoint `/predict/`  
Recibe datos de transacciones, aplica los filtros hechos en bronze y silver para alimentar el modelo. El output final son las predicciones del modelo mÃ¡s las variables 'Quantity', 'total', 'regroup_country', 'predictions', 'CustomerID' y 'fecha_procesamiento' con formato json:

La ingesta de datos sigue los siguientes pasos:
```1. ingresar datos como json en el POST /predict/
```
* Ejemplo:

ğŸ“¥ Entrada:
```json
[
  {
    "InvoiceNo": "536365",
    "StockCode": "85123A",
    "Quantity": 6,
    "UnitPrice": 2.55,
    "InvoiceDate": "12/1/2010 8:26",
    "CustomerID": 17850.0,
    "Country": "United Kingdom",
    "Description": "WHITE HANGING HEART T-LIGHT HOLDER"
  }
]
```

ğŸ“¤ Salida:
```json
{
  "data": [
    {
      "Quantity": 6,
      "total": 15.3,
      "regroup_country": 1,
      "predictions": 0,
      "CustomerID": "17850",
      "fecha_procesamiento": "2025-07-25T14:03:51.123Z"
    }
  ]
}



```
Cabe destacar, que cada vez que se hace ingresan datos, se llevan a cabo los siguientes filtros:
- Filtro de CustomerID nulo.
- Filtro de todos los registros que en la columna InvoiceNo que empiecen con "C".
- CreaciÃ³n de la columna "regroup_country" a partir de la columna "Country", donde 1 es para United Kingdom y 0 es para cualquier otro paÃ­s.
---

## ğŸ³ Docker

La API corre completamente en Docker: cada vez que se haga un Pull Request, se lleva a cabo un Build de Docker.

### Complementos:

```bash
docker-compose up --build
```

Para usar el contenedor debe tomar en cuenta la siguiente lÃ­nea:

"docker run -d -v "$(pwd)/model.pkl:/app/model.pkl" -p 8000:8000 coppelchallenge"

Ya que la imagen no se crea usando el modelo.
Una vez que corre la lÃ­nea anterior, la API estarÃ¡ disponible en el siguiente link:

```
http://localhost:8000/docs
```

---

## ğŸ§ª Tests

En cada PR se llevan a cabo los unit_test de la API y las funciones que usa (SilverClass y GoldClass)

```bash
pytest src/unit_test/
```

---

## ğŸ—‚ï¸ Estructura General

```
src/
â”œâ”€â”€ bronze/        # Ingesta de datos crudos
â”œâ”€â”€ silver/        # Transformaciones de limpieza
â”œâ”€â”€ gold/          # Feature engineering y creaciÃ³n de target
â”œâ”€â”€ complete_medallion/   # invocaciÃ³n de todas las funciones de bronze, silver y gold
â”œâ”€â”€ training/      # Entrenamiento de modelos
â”œâ”€â”€ app.py         # API FastAPI
â”œâ”€â”€ main.py        # Orquestador del pipeline completo
```

---

## ğŸ“„ Requisitos

InstalaciÃ³n de dependencias:

```bash
pip install -r requirements.txt
```

---

## ğŸ“Œ Notas Finales

- Base de datos local: `coppelchallenge.db`
- Modelo entrenado guardado como `model.pkl`
- Cada vez que se usa la API se genera un logging
---
